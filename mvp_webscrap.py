# -*- coding: utf-8 -*-
"""mvp_webscrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UP7kq0rnpY0T9T9z1Z-4-9pqQm-k0eQc
"""

!pip3 install beautifulsoup4
!pip install openpyxl

import pandas as pd
import requests as req
from bs4 import BeautifulSoup

import gspread
import os
import openpyxl as opyxl
from google.colab import drive
from datetime import datetime

# #auth.authenticate_user()
# from google.auth import default

url = "https://www.bna.com.ar/Personas"

headers = {}

req_response = req.get(url, headers = headers)

if req_response.status_code == 200:
  soup = BeautifulSoup(req_response.content, "html.parser")

tr_list = soup.find_all("tr")

for tr_element in tr_list:
  if tr_element.td and "Dolar U.S.A" in tr_element.td.text:                       # Me quedo solo con las etiquetas <td>
    moneda_compra_venta = tr_element.find_all("td", limit = 3)
    dolar_dic = {
        "moneda": moneda_compra_venta[0].text.strip(),
        "compra": moneda_compra_venta[1].text.strip(),
        "venta": moneda_compra_venta[2].text.strip()
    }
    break                                                                         # Forzamos terminar el for luego de encontrar el primer valor

df_dolar = pd.DataFrame([dolar_dic])
df_dolar

drive.mount('/content/drive')

ruta = '/content/drive/My Drive/Tasa/Web Scraping/dolar_bna.xlsx'


if os.path.exists(ruta):
  wb = opyxl.load_workbook(ruta)
  ws = wb.active
else:
  print("No se encontr√≥ el archivo en la ruta especificada. Crear manualmente")

fila = 1
while ws[f"G{fila}"].value is not None:
  fila += 1

ws[f"F{fila}"] = datetime.now().strftime("%Y-%m-%d")
ws[f"G{fila}"] = df_dolar.iloc[0][1]                           # Comprador
ws[f"J{fila}"] = df_dolar.iloc[0][2]                           # Vendedor

wb.save(ruta)